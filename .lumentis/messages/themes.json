[
  {
    "role": "user",
    "content": "<PrimarySource>\n{\\rtf1\\ansi\\ansicpg1252\\cocoartf2758\n\\cocoatextscaling0\\cocoaplatform0{\\fonttbl\\f0\\fswiss\\fcharset0 Helvetica;}\n{\\colortbl;\\red255\\green255\\blue255;}\n{\\*\\expandedcolortbl;;}\n\\paperw11900\\paperh16840\\margl1440\\margr1440\\vieww11520\\viewh8400\\viewkind0\n\\pard\\tx720\\tx1440\\tx2160\\tx2880\\tx3600\\tx4320\\tx5040\\tx5760\\tx6480\\tx7200\\tx7920\\tx8640\\pardirnatural\\partightenfactor0\n\n\\f0\\fs24 \\cf0 So we're going to start now. We can talk comfortably. And if you don't understand or if you don't understand something, we'll just jump in and ask questions. We'll do this on our own. So there are three concepts to explain. LLM and embedding. And we're going to explain what regs are. We made this for our parents. You know the Chet's PT. Chet's PT is called LLM. As we know, the weak point is the large language model. This model has a lot of data. We trained this model to have a lot of data. But why? We trained this model so that people can speak the language well. We call this LLM. The two important concepts are... Usually, the natural language in this industry is what we use. NLP is natural language processing. In the end, the problem is how to understand the machine. In this NLP, we keep thinking about how to recognize the language of people. But now the language model is in the process. People have to be so excited about this. For example, we have an air-conditioning box. The existing AR models are like screwdrivers. So it's really good to just loosen and tighten the screws. So if you develop an AR model, it's just one thing. So if you translate the language, the developer has to train the model according to that. Then that's all the model can do. But now that we develop a model that understands the language well, If he understands what I'm saying, he can do anything. So that's like the Swiss Army knife. You can do a lot of things with one tool. Now the focus of the developers has changed. So the biggest core of AI is the specific purpose. So the model that was very small in function It's a model that can change a lot of things at once. It's a revolution for AI. So we're general purpose intelligence. It's a function, but it's not just one thing. It means that we've made AI that can do all the general functions. I talk a lot about general purpose intelligence. Now, this is the LLM. Now, go back to GPT. This is something we talked about in the last video. It's a little familiar. The interesting part of GPT here is When GPT first came out, The main thing about GPT is In the end, it's a completion tool. It's a machine that has a complete function. What does that mean? If I enter a single, two-digit number, Then what he does is What kind of friend will come next? I'm going to calculate the probability. The highest probability is to turn it back to him. But if you do that, the question is The complete function is good, but what kind of purpose does it have? You can ask me. But if you use this well, for example, If we say this input that we input If we say this input, Of course, he thinks what the next word is. Then he'll turn the next word. Then I forgot what I said. Anyway, since it's a clock, it's a clock, so it's a clock. Even though they're doing a complete function, In fact, it's a language translation function. So it's very interesting here. If he's putting a complete function in the middle, The output we can turn is He can do whatever function we want. But what's really fun here is So OpenAI has a friend who has GPT completion function. He's back to training. But how he trained is that he brought people with him. He's kind of kind. He can speak in a conversation. He asked for feedback, and he's back to training. It's a GPT. People here forget a lot. Anyway, he's a complete function. So that's because we're doing it from engineering. There's a place where you touch the prompt. In the end, what you have to remember is just one thing. I remember that he has a complete function. So now, people have to use the prompt as much as they can. What does that mean? He's only complete anyway. How can he complete it? You have to teach him how to do it. He can do it now. I have to understand that. So I've registered this article here called Check Completion. He's a lot of people here. He's the owner of this person. We use a lot of the GPT, but the developers are not the best. The API is... If I use the program as a developer, I have to have the command and the program I want. We call it API. When I say, \"Hey, do this.\" The API is the bridge that the command will cross. The developer used software to arrive. The point here is that the developers used software to their program. But we connected GPT to GPT. We want to use the ability of GPT. We have to remember that he has the complete function. We have to give him the command. If we ask him this, he can't understand the complete function. What is the importance of the complete function? It's the importance of the context. What is the context without context? The context is Korean. Without context, it's a friend who can't get out. It's important to give context. What I heard from him is that I wrote the check Bt to him. I told him that I was going to give him a contract with Matilda for three lines. Without context. He said that. GPT is a friend who has the entire data on the Internet. So he thought of Matilda. Matilda is a very smart and confident friend. She likes to read and explains that she is a very intelligent friend. I asked him to ask him again. I told him to consider the next context and make a contract with Matilda for three lines. What I gave him was Matilda's song. Matilda is a woman who has a rich and tall body. Anyway, I gave him the context. Matilda explained Matilda's song. We have to remember that Matilda is a very sensitive friend. Matilda can talk well. Matilda can understand the context. The problem with these friends is that Matilda can get the amount of content. Matilda can understand the context. The basic word for talking is talking. But talking is not a word. It's a letter. Matilda can understand the context. Matilda can understand the context. Matilda can understand the context. Matilda can understand the context. Matilda can understand the context. Matilda can understand the context. Matilda can understand the context. Now, let's make a rake. You can do a rake with GPT. You can add information to GPT. When GPT works, you can ask GPT if GPT is working. Do you learn it by accepting it? You can connect the lag to the related area. You can connect the data base to the data of the area. You can connect the search engine to the data base. You can connect the data base to the GPT. You can connect the data base to the GPT. You can connect the data base to the GPT. You can connect the data base to the GPT. You can connect the data base to the GPT. You can connect the data base to the GPT. What is the program called? Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology. Rake is a technology.}\n</PrimarySource>\n\nPlease generate up to 10 possible keywords referring to industries, technologies, people or other themes for the data in PrimarySource. Return them as a JSON array of strings without markdown code blocks."
  }
]